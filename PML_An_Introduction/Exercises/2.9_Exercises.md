**Exercise 2.1**

a. The set $ii$ is sufficient for the calculation, because:
$$
P(H|e_1,e_2)=\frac{P(H)P(e_1,e_2|H)}{P(e1,e2)}
$$
according to the Bayes rule.

b. Both $i$ and $ii$ are sufficient now, because:
$$
E_1,E_2|H\rightarrow P(e_1,e_2|H)=P(e_1|H)P(e_2|H)
$$

**Exercise 2.2**

Suppose a tetrahedron dice where three faces are painted as red, green and blue,respectively, and the 4th face is painted with all three colors.

Any pair of variables are independent, for example:
$$
\begin{align*}
P(red\cap blue) &= P(red) * P(blue)\\
&=\frac{1}{2} * \frac{1}{2}\\
&=\frac{1}{4}
\end{align*}
$$
But:
$$
\begin{align*}
P(red\cap green\cap blue)\neq \frac{1}{8}
\end{align*}
$$
**Exercise 2.3**

(Reference from [StackExchange](https://stats.stackexchange.com/questions/125479/conditional-independence-iff-joint-factorizes))

If we integrate both sides in $x$:
$$
\int_Xp(x,y|z)dx=\int_Xg(x,z)h(y,z)dx
$$
This implies:
$$
p(y|z)=h(y,z)\int_Xg(x,z)dx
$$
And this tells us that:
$$
h(y,z)=p(y|z)\mu(z)
$$
And for $g$, we can also get:
$$
g(x,z)=p(x|z)\omega(z)
$$
Therefore,
$$
g(x,z)h(y,z)=p(y|z)\mu(z)p(x|z)\omega(z)
$$
Since both sides integrate to 1, we conclude with:
$$
\mu(z)\omega(z)=1
$$
So:
$$
p(x,y|z)=p(x|z)p(y|z)
$$
Therefore,
$$
X\perp Y|Z
$$
**Exercise 2.4**
$$
\begin{align*}
\mathcal{N}(x_1|\mu_1,\sigma_1^2)\otimes\mathcal{N}(x_2|\mu_2,\sigma_2^2) = 
\end{align*}
$$
